magrittr::set_colnames(c("prop_in_range", "area_m2_in_range",
"start_date", "end_date"))
}
#
area_low <- calculate_area_pixels(points_in_low) %>%
mutate(whoCat = "low")
area_mod <- calculate_area_pixels(points_in_mod) %>%
mutate(whoCat = "moderate")
area_high <- calculate_area_pixels(points_in_high) %>%
mutate(whoCat = "high")
area_veryhigh <- calculate_area_pixels(points_in_veryhigh) %>%
mutate(whoCat = "very_high")
# combine and re-level the category factor
all_areas <- bind_rows(area_low, area_mod, area_high, area_veryhigh) %>%
mutate(whoCat = forcats::fct_relevel(whoCat, c("very_high",
"high",
"moderate",
"low")))
}
# NOAA transform for CHAMPLAIN data
# valid as of 2019-02-01 metadata
transform_champlain_olci <- function(x){
# valid points: 2-249 is valid data
ifelse(x > 1 & x < 250,
10**(((3.0 / 250.0) * x) - 4.2),
NA)
}
# read the data
myraster <- raster::raster("./data/ts_2016.1007_1013.L4.LCHMP3.CIcyano.MAXIMUM_7day.tif")
## point to the bounding box
bb.path <- fs::path("./data/bb_miss.shp")
# run the function
area <- myraster %>% calc_area_by_thresholds(., bb.path,
"2016-10-07",
"2016-10-13",
"champlain_olci")
### calculates bloom size for WHO threshold bands within bounding box
calc_area_by_thresholds <- function(in.raster, boundingPolygon.path,
start_date, end_date,
lake_transform) {
# creates bounding polygon for work area
bb <- sf::read_sf(boundingPolygon.path)
# gets projection system from raster
ras.p4 <- sp::proj4string(in.raster)
# transforms bounding polygon to same projectoin as raster
bb.projected <- sf::st_transform(bb, ras.p4)
# calculates area of pixel from pixel resolution
raster.res <- res(in.raster)
pixel.area.m2 <- raster.res[1] * raster.res[2]
# creates point vector from raster
points.intersection <- as(in.raster,"SpatialPoints")
# create dataframe with column of raster values  from point vector
points.values <- data.frame(dn.val = raster::extract(in.raster,
points.intersection))
# redundant
# points.intersection$dn.val <- points.values
#
points.int.sf <- points.intersection %>% st_as_sf() %>%
sf::st_intersection(., bb.projected)
if(lake_transform == "champlain_olci"){
# valid points: 1-249 is valid data
# as of 2019-02-01 metadata
points_base <- points.int.sf %>%
mutate(index = transform_champlain_olci(dn.val))
} else if(lake_transform == "erie_olci"){
# valid points: 2-249 is valid data
# as of 2019-02-01 metadata
points_base <- points.int.sf %>%
mutate(index = transform_erie_olci(dn.val))
} else if(lake_transform == "erie_modis"){
points_base <- points.int.sf %>%
mutate(index = transform_erie_modis(dn.val))
} else {
stop("your lake transformation was not found")
}
# THRESHOLDS ----
# upper bounds on each - in units of CI (hence the divide by 1e8)
# data from from WHO tables
thresh.low <- 20000 / 1e8
thresh.mod <- 100000 / 1e8
thresh.high <- 10000000 / 1e8
#
points_in_low <- points_base %>%
filter(index < thresh.low)
points_in_mod <- points_base %>%
filter(index >= thresh.low & index < thresh.mod)
points_in_high <- points_base %>%
filter(index >= thresh.mod & index < thresh.high)
points_in_veryhigh <- points_base %>%
filter(index > thresh.high)
list_of_sfs <- c(points_in_low, points_in_mod,
points_in_high, points_in_veryhigh)
# calculate metrics for each set of sf points
calculate_area_pixels <- function(set_of_sfpoints){
baseline_denom <- points_base %>% filter(!is.na(index)) %>% nrow()
#
prop_in_range <- nrow(set_of_sfpoints) / baseline_denom
#
area_m2_in_range <- pixel.area.m2 * nrow(set_of_sfpoints)
toReturn <- data.frame(prop_in_range, area_m2_in_range,
start_date, end_date) %>%
magrittr::set_colnames(c("prop_in_range", "area_m2_in_range",
"start_date", "end_date"))
}
#
area_low <- calculate_area_pixels(points_in_low) %>%
mutate(whoCat = "low")
area_mod <- calculate_area_pixels(points_in_mod) %>%
mutate(whoCat = "moderate")
area_high <- calculate_area_pixels(points_in_high) %>%
mutate(whoCat = "high")
area_veryhigh <- calculate_area_pixels(points_in_veryhigh) %>%
mutate(whoCat = "very_high")
# combine and re-level the category factor
all_areas <- bind_rows(area_low, area_mod, area_high, area_veryhigh) %>%
mutate(whoCat = forcats::fct_relevel(whoCat, c("very_high",
"high",
"moderate",
"low")))
}
# NOAA transform for CHAMPLAIN data
# valid as of 2019-02-01 metadata
transform_champlain_olci <- function(x){
# valid points: 2-249 is valid data
ifelse(x > 1 & x < 250,
10**(((3.0 / 250.0) * x) - 4.2),
NA)
}
# read the data
myraster <- raster::raster("./data/ts_2016.1007_1013.L4.LCHMP3.CIcyano.MAXIMUM_7day.tif")
## point to the bounding box
bb.path <- fs::path("./data/bb_miss.shp")
# run the function
area <- myraster %>% calc_area_by_thresholds(., bb.path,
"2016-10-07",
"2016-10-13",
"champlain_olci")
library(tidyverse)
library(GISTools)
library(sf)
library(tmap)
?st_intersects
library(tidyverse)
library(GISTools)
library(sf)
library(tmap)
counties <- sf::read_sf("./data/County_Boundaries.shp") %>% sf::st_make_valid()
dams <- sf::read_sf("./data/Dam_or_Other_Blockage_Removed_2012_2017.shp") %>% sf::st_make_valid()
dams <- sf::read_sf("./data/Dam_or_Other_Blockage_Removed_2012_2017.shp") %>% sf::st_make_valid()
streams <- sf::read_sf("./data/Streams_Opened_by_Dam_Removal_2012_2017.shp") %>% sf::st_make_valid()
pa.counties <- counties %>% filter(STATEFP10 == 42)
pa.dams <- dams[pa.counties,]
pa.dams2 <- st_intersection(dams, pa.counties)
pa.dams <- st_intersection(dams, pa.counties)
st_intersects(dams, pa.counties)
does.it <- st_intersects(dams, pa.counties)
rm(does.it)
dams %>% st_intersects(x = ., y = pa.counties)
dams %>% st_intersects(x = pa.counties, y = .)
dams %>% st_intersects(x = ., y = pa.counties, sparse = FALSE)
dams %>% st_disjoint(x = ., y = pa.counties, sparse = FALSE)
dams %>% st_within(x = ., y = pa.counties, sparse = FALSE)
c.tioga <- pa.counties %>% filter(NAME10 == "Tioga")
streams.tioga <- streamm[c.tioga,]
streams.tioga <- streams[c.tioga,]
streams.tioga %>% st_covered_by(., c.tioga)
tm_shape(c.tioga) + tm_polygons() + tm_shape(streams.tioga) + tm_lines(col = "blue")
streams.tioga %>% st_is_within_distance(., dams, 1)
library(tidyverse)
library(sf)
library(tmap)
# NHDs
nhds <- sf::read_sf("./data/nhdplus_loads.shp") %>% sf::st_make_valid()
glimpse(nhds)
tm_shape(nhds) + tm_polygons("Baseline_L", n = 10)
tmap_mode("view")
tm_shape(nhds) + tm_polygons("Baseline_L", n = 10)
# RPCs
rpcs <- sf::read_sf("./data/gn_vt_rpcs.shp") %>% sf::st_make_valid()
glimpse(rpcs)
tm_shape(rpcs) + tm_polygons(col = "INITIALS")
# overlay nhd and rpc
tm_shape(rpcs) + tm_borders(col = "red") +
tm_shape(nhds) + tm_polygons(col = "Baseline_L", n = 7) +
tm_shape(rpcs) + tm_borders(col = "red")
tmap_mode('plot')
# overlay nhd and rpc
tm_shape(rpcs) + tm_borders(col = "red") +
tm_shape(nhds) + tm_polygons(col = "Baseline_L", n = 7) +
tm_shape(rpcs) + tm_borders(col = "red")
tmap_mode("view")
") +
tm_shape(nhds) + tm_polygons(col = "Baseline_L", n = 7) +
tm_shape(rpcs) + tm_borders(col = "red")
tm_shape(rpcs) + tm_borders(col = "red") +
tm_shape(nhds) + tm_polygons(col = "Baseline_L", n = 7) +
tm_shape(rpcs) + tm_borders(col = "red")
# do the join
nhd_rpcs <- st_join(nhds, rpcs, join = st_intersects)
# look at it/confirm it worked
glimpse(nhd_rpcs)
# plot it
tm_shape(nhd_rpcs) + tm_polygons(col = "RPC")
nhd_rpcs %>%
group_by(RPC) %>%
summarize(totalLoad = sum(Baseline_L))
# the "tidy way"
nhd_rpcs %>%
group_by(RPC) %>%
summarize(totalLoad = sum(Baseline_L)) %>%
tm_shape(.) + tm_polygons(col = "totalLoad")
# using aggregate instead
aggregate(x = nhds, by = rpcs, FUN = sum) # throws an error... what's the problem?
glimpse(nhds)
# using aggregate instead
nhds %>% dplyr::select(-SOURCEFC, -NHDPlus_Ca, -Tactical_B) %>%
aggregate(x = ., by = rpcs, FUN = sum)
# using aggregate instead
agg.rpcs <- nhds %>% dplyr::select(-SOURCEFC, -NHDPlus_Ca, -Tactical_B) %>%
aggregate(x = ., by = rpcs, FUN = sum)
# plot
tm_shape(agg.rpcs) + tm_polygons(col = "Baseline_L")
nhd_rpcs %>% group_by(NHDPlus_ID) %>% summarise(count = n()) %>%
arrange(desc(count))
# area-weighted interpolation
interp.loads <- nhds %>% dplyr::select(Baseline_L, geometry) %>%
st_interpolate_aw(., rpcs, extensive = T)
tm_shape(interp.loads) + tm_polygons(col = "Baseline_L")
# do a join
comparison <- st_join(agg.rpcs, interp.loads, st_equals)
# calculate the error, then map it
comparison %>% mutate(diff = Baseline_L.x - Baseline_L.y) %>%
tm_shape(.) + tm_polygons(col = "diff") +
tm_shape(nhds) + tm_borders(col = "blue")
knitr::opts_chunk$set(echo = TRUE)
library(sf)
library(terra)
library(dplyr)
library(spData)
library(spDataLarge)
install.packages("spDataLarge")
data(seine)
force(seine)
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(sf)
library(terra)
library(dplyr)
library(spData)
data(seine)
knitr::opts_chunk$set(echo = TRUE)
#libraries
library(sf)
library(terra)
library(dplyr)
library(spData)
#data
data(seine)
#View original data
plot(seine)
library(tmap)
#View original data
tm_shape(seine) + tm_lines(col = "black")
#simplify the gometry
seine_simp = st_simplify(seine, dTolerance = 2000)  # 2000 m
tmap_arrange(orig, simple, ncol = 2)
#View original data
orig <- tm_shape(seine) + tm_lines(col = "black")
orig
#simplify the gometry
seine_simp = st_simplify(seine, dTolerance = 2000)  # 2000 m
#view new data next to original data
simple <- tm_shape(seine) + tm_lines(col = "black")
tmap_arrange(orig, simple, ncol = 2)
#View original data
orig <- tm_shape(seine) + tm_lines(col = "black") + tm_layout(title = "Original")
orig
#simplify the gometry
seine_simp = st_simplify(seine, dTolerance = 2000)  # 2000 m
#view new data next to original data
simplify <- tm_shape(seine) + tm_lines(col = "black") + tm_layout(title = "Simplified")
tmap_arrange(orig, simplify, ncol = 2)
#see next chunk for size comparison
#original disk size
orig.disk <- object.size(seine)
print("Original disk size = ", orig.disk)
print(orig.disk)
#original disk size
orig.disk <- object.size(seine)
print("Original disk size")
print(orig.disk)
#simplified disk size
simp.disk <- object.size(seine_simp)
print("Simplified disk size")
print(simp.disk)
knitr::opts_chunk$set(echo = TRUE)
#libraries
library(sf)
library(terra)
library(dplyr)
library(spData)
library(tmap)
#data
data(seine)
nz_sfc = st_geometry(nz)
#use nz_sfc with a vector to shift
nz_sfc = st_geometry(nz)
#uncomment code below and create shift
# nz_shift <-
plot(nz_shift)
#uncomment code below and create shift
nz_shift <-nz_sfc + c(300, -500)
plot(nz_shift)
plot(nz_sfc, add = TRUE)
?plot
plot(nz_shift)
plot(nz_sfc, add = TRUE)
#use nz_sfc with a vector to shift
nz_sfc = st_geometry(nz)
#uncomment code below and create shift
nz_shift <-nz_sfc + c(3000, -5000)
#uncomment code below to map shift
tm_shape(nz_sfc) + tm_polygons(col = "gray") +
tm_shape(nz_shift) + tm_polygons(col = "red")
tm_shape(nz_shift) + tm_polygons(col = "red")
#uncomment code below to map shift
tm_shape(nz_sfc) + tm_polygons(col = "gray") + tm_shape(nz_shift) + tm_polygons(col = "red")
+ tm_shape(nz_shift) + tm_borders(col = "red")
#uncomment code below to map shift
tm_shape(nz_sfc) + tm_polygons(col = "gray") +
tm_shape(nz_shift) + tm_borders(col = "red")
install.packages("swirl")
swirl()
library(swirl)
swirl()
library(tmap)
library(tidyverse)
library(raster)
library(tmap)
myras <- raster::raster("./data/ts_2016.1007_1013.L4.LCHMP3.CIcyano.MAXIMUM_7day.tif")
plot(myras)
myras * 2
myras %>% values() %>% range(na.rm = T)
# What's different here?
(myras * 2) %>% values() %>% range(na.rm = T)
rcl = matrix(c(0, 1, 0, 2, 249, 1, 250, 256, 0), ncol = 3, byrow = TRUE)
rcl
require(rgdal)
validdata = reclassify(myras, rcl = rcl)
validdata
plot(validdata)
# The input file geodatabase
fgdb <- "./data/gSSURGO_NE.gdb"
# List all feature classes in a file geodatabase
subset(ogrDrivers(), grepl("GDB", name))
fc_list <- ogrListLayers(fgdb)
print(fc_list)
validRaster <- myras * validdata
plot(validRaster)
# NOAA transform for CHAMPLAIN data
# valid as of 2019-02-01 metadata
transform_champlain_olci <- function(x){
10**(((3.0 / 250.0) * x) - 4.2)
}
myras.ci <- validRaster %>% transform_champlain_olci
plot(myras.ci)
# Read the feature class
fc <- readOGR(dsn=fgdb,layer="MUPOLYGON")
# Determine the FC extent, projection, and attribute information
summary(fc)
# View the feature class
plot(fc)
# View the feature class
tm_shape(fc) + tm_polygons()
# Read the feature class
fc <- readOGR(dsn=fgdb,layer="MUPOLYGON")
myras_focal = focal(myras.ci, w = matrix(1, nrow = 3, ncol = 3), fun = max)
plot(myras_focal)
(myras_focal - r_focal) %>% plot
(myras_focal - myras.ci) %>% plot
# good practice
compareRaster(myras_focal, myras.ci)
soils <- raster::raster("./data/gSSURGO_NE.gdb/MapunitRaster_10m")
myrasSep <- raster::raster("./data/ts_2016.0902_0908.L4.LCHMP3.CIcyano.MAXIMUM_7day.tif")
myrasOct <- raster::raster("./data/ts_2016.1007_1013.L4.LCHMP3.CIcyano.MAXIMUM_7day.tif")
# blooms get larger?
compare(myrasSep, myrasOct)
# blooms get larger?
compareRaster(myrasSep, myrasOct)
# blooms get larger?
recSep <- reclassify(myrasSep, rcl = rcl)
recOct <- reclassify(myrasOct, rcl = rcl)
# Determine the FC extent, projection, and attribute information
summary(fc)
# The input file geodatabase
fgdb <- "./data/gSSURGO_NE.gdb"
# List all feature classes in a file geodatabase
subset(ogrDrivers(), grepl("GDB", name))
fc_list <- ogrListLayers(fgdb)
print(fc_list)
install.packages("leaflet")
library(tidyverse)
library(leaflet)
m <- leaflet()
m
m <- leaflet() %>%
addTiles()
m
m
m <- leaflet() %>%
addTiles() %>%  # Add default OpenStreetMap map tiles
addMarkers(lng = -96.703090, lat = 40.819288, popup="The Burnett Hall GIS Lab")
m
df <- data.frame(
lat = rnorm(100),
lng = rnorm(100),
size = runif(100, 5, 20),
color = sample(colors(), 100)
)
m2 <- leaflet(df) %>% addTitles()
m2 <- leaflet(df) %>% addTiles()
m2
glimpse(m2)
m2$x
m2 %>% addCircleMarkers(radius = ~size, color = ~color, fill = FALSE)
m2 %>% addCircleMarkers(radius = runif(100, 4, 10), color = c('red'))
m2 %>% addCircleMarkers(radius = ~size, color = ~color, fill = FALSE)
m2 %>% addCircleMarkers(radius = runif(100, 4, 10), color = c('red'))
m <- leaflet() %>% setView(lng = -96.703090, lat = 40.81928, zoom = 14)
m %>% addTiles()
m %>% addProviderTiles(providers$CartoDB.PositronNoLabels)
m %>% addProviderTiles(providers$OpenRailwayMap)
library(sf)
parks <- sf::read_sf("./data/State_Park_Locations.shp")
# set up the map, zoom out a bit
mp <- leaflet(data = parks) %>% setView(lng = -96.703090, lat = 40.81928, zoom = 10)
mp %>% addTiles() %>%
addMarkers(popup = ~AreaName, label = ~AreaName)
?
1
?paste0
streams <- sf::read_sf("./data/Streams_303_d_.shp")
ms <- leaflet(data = streams) %>%
setView(lng = -96.703090, lat = 40.81928, zoom = 10) %>%
addTiles() %>%
addPolylines(., color = "blue",
popup = ~paste0(Waterbody_, " - ", Impairment))
ms <- leaflet(data = streams) %>%
setView(lng = -96.703090, lat = 40.81928, zoom = 10) %>%
addTiles() %>%
addPolylines(., color = "blue",
popup = ~paste0(Waterbody_, " - ", Impairment))
streams <- sf::read_sf("./data/Streams_303_d_.shp")
ms <- leaflet(data = streams) %>%
setView(lng = -96.703090, lat = 40.81928, zoom = 10) %>%
addTiles() %>%
addPolylines(., color = "blue",
popup = ~paste0(Waterbody_, " - ", Impairment))
ms
# do multiple layers by not passing the first "leaflet()" call a data argument
m.both <- leaflet() %>%
setView(lng = -96.703090, lat = 40.81928, zoom = 10) %>%
addProviderTiles(providers$Esri.NatGeoWorldMap) %>%
addMarkers(data = parks, popup = ~AreaName, label = ~AreaName) %>%
addPolylines(data = streams, color = "blue",
popup = ~paste0(Waterbody_, " - ", Impairment))
m.both
# do multiple layers by not passing the first "leaflet()" call a data argument
m.both <- leaflet() %>%
setView(lng = -96.703090, lat = 40.81928, zoom = 10) %>%
addProviderTiles(providers$Thunderforest.Outdoors) %>%
addMarkers(data = parks, popup = ~AreaName, label = ~AreaName) %>%
addPolylines(data = streams, color = "blue",
popup = ~paste0(Waterbody_, " - ", Impairment))
m.both
# do multiple layers by not passing the first "leaflet()" call a data argument
m.both <- leaflet() %>%
setView(lng = -96.703090, lat = 40.81928, zoom = 10) %>%
addProviderTiles(providers$Stamen.Toner) %>%
addMarkers(data = parks, popup = ~AreaName, label = ~AreaName) %>%
addPolylines(data = streams, color = "blue",
popup = ~paste0(Waterbody_, " - ", Impairment))
m.both
lanc <- sf::st_read("./data/lancaster_county.shp")
muni <- st_read("./data/Municipal_Boundaries.shp")
lanc.muni <- muni[lanc,]
lanc <- sf::st_read("./data/lancaster_county.shp") %>% st_make_valid()
muni <- st_read("./data/Municipal_Boundaries.shp") %>% st_make_valid()
lanc.muni <- muni[lanc,]
m3 <- leaflet() %>%
setView(lng = -96.703090, lat = 40.81928, zoom = 10) %>%
addProviderTiles(providers$Stamen.Toner) %>%
addMarkers(data = parks, popup = ~AreaName, label = ~AreaName) %>%
addPolylines(data = streams, color = "blue",
popup = ~paste0(Waterbody_, " - ", Impairment)) %>%
addPolygons(data=lanc.muni, popup = ~NAMESLAD, fillColor = "green")
m3 <- leaflet() %>%
setView(lng = -96.703090, lat = 40.81928, zoom = 10) %>%
addProviderTiles(providers$Stamen.Toner) %>%
addMarkers(data = parks, popup = ~AreaName, label = ~AreaName) %>%
addPolylines(data = streams, color = "blue",
popup = ~paste0(Waterbody_, " - ", Impairment)) %>%
addPolygons(data=lanc.muni, popup = ~NAMELSAD, fillColor = "green")
m3
m3 <- leaflet() %>%
setView(lng = -96.703090, lat = 40.81928, zoom = 10) %>%
addProviderTiles(providers$Stamen.Toner) %>%
addMarkers(data = parks, popup = ~AreaName, label = ~AreaName) %>%
addPolylines(data = streams, color = "blue",
popup = ~paste0(Waterbody_, " - ", Impairment)) %>%
addPolygons(data=lanc.muni, popup = ~NAMELSAD, fillColor = "green", color = "red")
m3
