tm_shape(counties) + tm_polygons() +
tm_shape(lc) + tm_polygons(col = "red") +
tm_shape(lc_303ds) + tm_lines(col = "blue") +
tm_shape(lc_303) + tm_lines(col = "yellow")
tm_shape(counties) + tm_polygons() +
tm_shape(lc) + tm_polygons(col = "red") +
tm_shape(lc_303) + tm_lines(col = "blue") +
tm_shape(lc_303ds) + tm_lines(col = "yellow")
#subset with spatial index
lc_303 <- streams[lc,]
#combine plots
tm_shape(lc_303) + tm_lines(col = "Waterbody_") +
tm_shape(lc_parks) + tm_dots(col = "AreaName", size = 1)
#libraries
library(tidyverse)
#libraries
library(tidyverse)
library(sf)
library(GISTools)
library(tmap)
#data
streams <- sf::read_sf("./data/Streams_303_d_.shp")
counties <- sf::read_sf("./data/County_Boundaries-_Census.shp")
tm_shape(streams) + tm_lines()
counties_areas <- sf::st_area(counties)
counties <- counties %>% mutate(area = sf::st_area(counties))
#filter
lc <- counties %>% dplyr::filter(., NAME10 == "Lancaster")
#subset with spatial index
lc_303 <- streams[lc,]
#subset with intersection
lc_303ds <- sf::st_intersection(streams, lc)
tm_shape(counties) + tm_polygons() +
tm_shape(lc) + tm_polygons(col = "red") +
tm_shape(lc_303) + tm_lines(col = "blue") +
tm_shape(lc_303ds) + tm_lines(col = "yellow")
#buffer
lc_303ds.crs <- sf::st_crs(lc_303ds)
lc_303ds.crs
buffs <- sf::st_buffer(lc_303ds, dist = 1000)
tm_shape(buffs) + tm_polygons(col = "Waterbody_")
#parks
parks <- sf::read_sf("./data/State_Park_Locations.shp")
#subset to lc
lc_parks <- sf::st_intersection(parks, lc)
#plot parks
tm_shape(lc_parks) + tm_dots(col = "AreaName", size = 1)
#combine plots
tm_shape(lc_303) + tm_lines(col = "Waterbody_") +
tm_shape(lc_parks) + tm_dots(col = "AreaName", size = 1)
#final task
streams.feet <- sf::st_transform(streams, 102704)
sf::st_crs(streams.feet)
buff_streams <- sf::st_buffer(streams, dist = 800) #800 meters equals 1/2 mile
park_stream <- sf::st_intersection(buff_streams, parks)
tm_shape(park_stream) + tm_dots(col = "Waterbody_", size = 2)
sessionInfo()
#GISTools
poly.areas(counties)
counties %>% as_Spatial() %>% poly.areas()
crs(counties)
st_crs(counties)
"Rmpi" %in% loadedNamespaces()
parks_p <- sf::st_transform(parks, 26914)
counties_p <- sf::st_transform(counties, 26914)
counties %>% st::st_transform(., 26914) %>% st::st_area()
counties_p %>% as_Spatial() %>% poly.areas()
counties %>% sf::st_transform(., 26914) %>% sf::st_area()
counties %>% sf::st_transform(., 6880) %>% sf::st_area()
c.area <- counties %>% sf::st_transform(., 6880) %>% sf::st_area()
class(c.area)
counties %>% sf::st_transform(., 26914) %>% sf::st_area()
lc_303ds_p <- sf::st_transform(lc_303ds, 26914)
lc_parks_p <- sf::st_transform(lc_parks, 26914)
sf::st_distance(lc_303ds_p, lc_parks_p)
t <- sf::st_distance(lc_303ds_p, lc_parks_p)
class(t)
dist_proj <- sf::st_distance(lc_303ds_p, lc_parks_p)
st_crs(lc_303ds)
dist_unpr <- sf::st_distance(lc_303ds, lc_parks)
dist_unpr
dist_proj
dist_diff <- dist_proj - dist_unpr
dist_diff
ggplot(data = dist_diff) +
geom_histogram()
dist_diff <- as_vector(dist_proj - dist_unpr)
dist_diff
ggplot(data = dist_diff) +
geom_histogram()
dist_diff <- as.data.frame(dist_proj - dist_unpr)
dist_diff
ggplot(data = dist_diff) +
geom_histogram()
dist_diff <- as_tibble(dist_proj - dist_unpr)
dist_diff
ggplot(data = dist_diff) +
geom_histogram()
dist_diff <- dist_proj - dist_unpr
hist(dist_diff)
library(tidyverse)
library(GISTools)
Library(sf)
library(sf)
library(tmap)
precip <- sf::read_sf("./data/Precip2008Readings.shp")
neb <- sf::read_sf("./data/Nebraska_State_Boundary.shp")
tmap_mode("view")
tm_shape(neb) + tm_polygons() + tm_shape(precip) + tm_dots(col = "navyblue")
library(raster)
library(tidyverse)
library(sf)
### calculates bloom size for WHO threshold bands within bounding box
calc_area_by_thresholds <- function(in.raster, boundingPolygon.path,
start_date, end_date,
lake_transform) {
#
bb <- sf::read_sf(boundingPolygon.path)
#
ras.p4 <- sp::proj4string(in.raster)
#
bb.projected <- sf::st_transform(bb, ras.p4)
#
raster.res <- res(in.raster)
pixel.area.m2 <- raster.res[1] * raster.res[2]
#
points.intersection <- as(in.raster,"SpatialPoints")
#
points.values <- data.frame(dn.val = raster::extract(in.raster,
points.intersection))
#
points.intersection$dn.val <- points.values
#
points.int.sf <- points.intersection %>% st_as_sf() %>%
sf::st_intersection(., bb.projected)
if(lake_transform == "champlain_olci"){
# valid points: 1-249 is valid data
# as of 2019-02-01 metadata
points_base <- points.int.sf %>%
mutate(index = transform_champlain_olci(dn.val))
} else if(lake_transform == "erie_olci"){
# valid points: 2-249 is valid data
# as of 2019-02-01 metadata
points_base <- points.int.sf %>%
mutate(index = transform_erie_olci(dn.val))
} else if(lake_transform == "erie_modis"){
points_base <- points.int.sf %>%
mutate(index = transform_erie_modis(dn.val))
} else {
stop("your lake transformation was not found")
}
# THRESHOLDS ----
# upper bounds on each - in units of CI (hence the divide by 1e8)
# data from from WHO tables
thresh.low <- 20000 / 1e8
thresh.mod <- 100000 / 1e8
thresh.high <- 10000000 / 1e8
#
points_in_low <- points_base %>%
filter(index < thresh.low)
points_in_mod <- points_base %>%
filter(index >= thresh.low & index < thresh.mod)
points_in_high <- points_base %>%
filter(index >= thresh.mod & index < thresh.high)
points_in_veryhigh <- points_base %>%
filter(index > thresh.high)
list_of_sfs <- c(points_in_low, points_in_mod,
points_in_high, points_in_veryhigh)
# calculate metrics for each set of sf points
calculate_area_pixels <- function(set_of_sfpoints){
baseline_denom <- points_base %>% filter(!is.na(index)) %>% nrow()
#
prop_in_range <- nrow(set_of_sfpoints) / baseline_denom
#
area_m2_in_range <- pixel.area.m2 * nrow(set_of_sfpoints)
toReturn <- data.frame(prop_in_range, area_m2_in_range,
start_date, end_date) %>%
magrittr::set_colnames(c("prop_in_range", "area_m2_in_range",
"start_date", "end_date"))
}
#
area_low <- calculate_area_pixels(points_in_low) %>%
mutate(whoCat = "low")
area_mod <- calculate_area_pixels(points_in_mod) %>%
mutate(whoCat = "moderate")
area_high <- calculate_area_pixels(points_in_high) %>%
mutate(whoCat = "high")
area_veryhigh <- calculate_area_pixels(points_in_veryhigh) %>%
mutate(whoCat = "very_high")
# combine and re-level the category factor
all_areas <- bind_rows(area_low, area_mod, area_high, area_veryhigh) %>%
mutate(whoCat = forcats::fct_relevel(whoCat, c("very_high",
"high",
"moderate",
"low")))
}
# NOAA transform for CHAMPLAIN data
# valid as of 2019-02-01 metadata
transform_champlain_olci <- function(x){
# valid points: 2-249 is valid data
ifelse(x > 1 & x < 250,
10**(((3.0 / 250.0) * x) - 4.2),
NA)
}
# read the data
myraster <- raster::raster("./data/ts_2016.1007_1013.L4.LCHMP3.CIcyano.MAXIMUM_7day.tif")
## point to the bounding box
bb.path <- fs::path("./data/bb_miss.shp")
# run the function
area <- myraster %>% calc_area_by_thresholds(., bb.path,
"2016-10-07",
"2016-10-13",
"champlain_olci")
### calculates bloom size for WHO threshold bands within bounding box
calc_area_by_thresholds <- function(in.raster, boundingPolygon.path,
start_date, end_date,
lake_transform) {
# creates bounding polygon for work area
bb <- sf::read_sf(boundingPolygon.path)
# gets projection system from raster
ras.p4 <- sp::proj4string(in.raster)
# transforms bounding polygon to same projectoin as raster
bb.projected <- sf::st_transform(bb, ras.p4)
# calculates area of pixel from pixel resolution
raster.res <- res(in.raster)
pixel.area.m2 <- raster.res[1] * raster.res[2]
# creates point vector from raster
points.intersection <- as(in.raster,"SpatialPoints")
# create dataframe with column of raster values  from point vector
points.values <- data.frame(dn.val = raster::extract(in.raster,
points.intersection))
# redundant
# points.intersection$dn.val <- points.values
#
points.int.sf <- points.intersection %>% st_as_sf() %>%
sf::st_intersection(., bb.projected)
if(lake_transform == "champlain_olci"){
# valid points: 1-249 is valid data
# as of 2019-02-01 metadata
points_base <- points.int.sf %>%
mutate(index = transform_champlain_olci(dn.val))
} else if(lake_transform == "erie_olci"){
# valid points: 2-249 is valid data
# as of 2019-02-01 metadata
points_base <- points.int.sf %>%
mutate(index = transform_erie_olci(dn.val))
} else if(lake_transform == "erie_modis"){
points_base <- points.int.sf %>%
mutate(index = transform_erie_modis(dn.val))
} else {
stop("your lake transformation was not found")
}
# THRESHOLDS ----
# upper bounds on each - in units of CI (hence the divide by 1e8)
# data from from WHO tables
thresh.low <- 20000 / 1e8
thresh.mod <- 100000 / 1e8
thresh.high <- 10000000 / 1e8
#
points_in_low <- points_base %>%
filter(index < thresh.low)
points_in_mod <- points_base %>%
filter(index >= thresh.low & index < thresh.mod)
points_in_high <- points_base %>%
filter(index >= thresh.mod & index < thresh.high)
points_in_veryhigh <- points_base %>%
filter(index > thresh.high)
list_of_sfs <- c(points_in_low, points_in_mod,
points_in_high, points_in_veryhigh)
# calculate metrics for each set of sf points
calculate_area_pixels <- function(set_of_sfpoints){
baseline_denom <- points_base %>% filter(!is.na(index)) %>% nrow()
#
prop_in_range <- nrow(set_of_sfpoints) / baseline_denom
#
area_m2_in_range <- pixel.area.m2 * nrow(set_of_sfpoints)
toReturn <- data.frame(prop_in_range, area_m2_in_range,
start_date, end_date) %>%
magrittr::set_colnames(c("prop_in_range", "area_m2_in_range",
"start_date", "end_date"))
}
#
area_low <- calculate_area_pixels(points_in_low) %>%
mutate(whoCat = "low")
area_mod <- calculate_area_pixels(points_in_mod) %>%
mutate(whoCat = "moderate")
area_high <- calculate_area_pixels(points_in_high) %>%
mutate(whoCat = "high")
area_veryhigh <- calculate_area_pixels(points_in_veryhigh) %>%
mutate(whoCat = "very_high")
# combine and re-level the category factor
all_areas <- bind_rows(area_low, area_mod, area_high, area_veryhigh) %>%
mutate(whoCat = forcats::fct_relevel(whoCat, c("very_high",
"high",
"moderate",
"low")))
}
# NOAA transform for CHAMPLAIN data
# valid as of 2019-02-01 metadata
transform_champlain_olci <- function(x){
# valid points: 2-249 is valid data
ifelse(x > 1 & x < 250,
10**(((3.0 / 250.0) * x) - 4.2),
NA)
}
# read the data
myraster <- raster::raster("./data/ts_2016.1007_1013.L4.LCHMP3.CIcyano.MAXIMUM_7day.tif")
## point to the bounding box
bb.path <- fs::path("./data/bb_miss.shp")
# run the function
area <- myraster %>% calc_area_by_thresholds(., bb.path,
"2016-10-07",
"2016-10-13",
"champlain_olci")
library(tidyverse)
library(GISTools)
library(sf)
library(tmap)
?st_intersects
library(tidyverse)
library(GISTools)
library(sf)
library(tmap)
counties <- sf::read_sf("./data/County_Boundaries.shp") %>% sf::st_make_valid()
dams <- sf::read_sf("./data/Dam_or_Other_Blockage_Removed_2012_2017.shp") %>% sf::st_make_valid()
dams <- sf::read_sf("./data/Dam_or_Other_Blockage_Removed_2012_2017.shp") %>% sf::st_make_valid()
streams <- sf::read_sf("./data/Streams_Opened_by_Dam_Removal_2012_2017.shp") %>% sf::st_make_valid()
pa.counties <- counties %>% filter(STATEFP10 == 42)
pa.dams <- dams[pa.counties,]
pa.dams2 <- st_intersection(dams, pa.counties)
pa.dams <- st_intersection(dams, pa.counties)
st_intersects(dams, pa.counties)
does.it <- st_intersects(dams, pa.counties)
rm(does.it)
dams %>% st_intersects(x = ., y = pa.counties)
dams %>% st_intersects(x = pa.counties, y = .)
dams %>% st_intersects(x = ., y = pa.counties, sparse = FALSE)
dams %>% st_disjoint(x = ., y = pa.counties, sparse = FALSE)
dams %>% st_within(x = ., y = pa.counties, sparse = FALSE)
c.tioga <- pa.counties %>% filter(NAME10 == "Tioga")
streams.tioga <- streamm[c.tioga,]
streams.tioga <- streams[c.tioga,]
streams.tioga %>% st_covered_by(., c.tioga)
tm_shape(c.tioga) + tm_polygons() + tm_shape(streams.tioga) + tm_lines(col = "blue")
streams.tioga %>% st_is_within_distance(., dams, 1)
library(tidyverse)
library(sf)
library(tmap)
# NHDs
nhds <- sf::read_sf("./data/nhdplus_loads.shp") %>% sf::st_make_valid()
glimpse(nhds)
tm_shape(nhds) + tm_polygons("Baseline_L", n = 10)
tmap_mode("view")
tm_shape(nhds) + tm_polygons("Baseline_L", n = 10)
# RPCs
rpcs <- sf::read_sf("./data/gn_vt_rpcs.shp") %>% sf::st_make_valid()
glimpse(rpcs)
tm_shape(rpcs) + tm_polygons(col = "INITIALS")
# overlay nhd and rpc
tm_shape(rpcs) + tm_borders(col = "red") +
tm_shape(nhds) + tm_polygons(col = "Baseline_L", n = 7) +
tm_shape(rpcs) + tm_borders(col = "red")
tmap_mode('plot')
# overlay nhd and rpc
tm_shape(rpcs) + tm_borders(col = "red") +
tm_shape(nhds) + tm_polygons(col = "Baseline_L", n = 7) +
tm_shape(rpcs) + tm_borders(col = "red")
tmap_mode("view")
") +
tm_shape(nhds) + tm_polygons(col = "Baseline_L", n = 7) +
tm_shape(rpcs) + tm_borders(col = "red")
tm_shape(rpcs) + tm_borders(col = "red") +
tm_shape(nhds) + tm_polygons(col = "Baseline_L", n = 7) +
tm_shape(rpcs) + tm_borders(col = "red")
# do the join
nhd_rpcs <- st_join(nhds, rpcs, join = st_intersects)
# look at it/confirm it worked
glimpse(nhd_rpcs)
# plot it
tm_shape(nhd_rpcs) + tm_polygons(col = "RPC")
nhd_rpcs %>%
group_by(RPC) %>%
summarize(totalLoad = sum(Baseline_L))
# the "tidy way"
nhd_rpcs %>%
group_by(RPC) %>%
summarize(totalLoad = sum(Baseline_L)) %>%
tm_shape(.) + tm_polygons(col = "totalLoad")
# using aggregate instead
aggregate(x = nhds, by = rpcs, FUN = sum) # throws an error... what's the problem?
glimpse(nhds)
# using aggregate instead
nhds %>% dplyr::select(-SOURCEFC, -NHDPlus_Ca, -Tactical_B) %>%
aggregate(x = ., by = rpcs, FUN = sum)
# using aggregate instead
agg.rpcs <- nhds %>% dplyr::select(-SOURCEFC, -NHDPlus_Ca, -Tactical_B) %>%
aggregate(x = ., by = rpcs, FUN = sum)
# plot
tm_shape(agg.rpcs) + tm_polygons(col = "Baseline_L")
nhd_rpcs %>% group_by(NHDPlus_ID) %>% summarise(count = n()) %>%
arrange(desc(count))
# area-weighted interpolation
interp.loads <- nhds %>% dplyr::select(Baseline_L, geometry) %>%
st_interpolate_aw(., rpcs, extensive = T)
tm_shape(interp.loads) + tm_polygons(col = "Baseline_L")
# do a join
comparison <- st_join(agg.rpcs, interp.loads, st_equals)
# calculate the error, then map it
comparison %>% mutate(diff = Baseline_L.x - Baseline_L.y) %>%
tm_shape(.) + tm_polygons(col = "diff") +
tm_shape(nhds) + tm_borders(col = "blue")
knitr::opts_chunk$set(echo = TRUE)
library(sf)
library(terra)
library(dplyr)
library(spData)
library(spDataLarge)
install.packages("spDataLarge")
data(seine)
force(seine)
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(sf)
library(terra)
library(dplyr)
library(spData)
data(seine)
knitr::opts_chunk$set(echo = TRUE)
#libraries
library(sf)
library(terra)
library(dplyr)
library(spData)
#data
data(seine)
#View original data
plot(seine)
library(tmap)
#View original data
tm_shape(seine) + tm_lines(col = "black")
#simplify the gometry
seine_simp = st_simplify(seine, dTolerance = 2000)  # 2000 m
tmap_arrange(orig, simple, ncol = 2)
#View original data
orig <- tm_shape(seine) + tm_lines(col = "black")
orig
#simplify the gometry
seine_simp = st_simplify(seine, dTolerance = 2000)  # 2000 m
#view new data next to original data
simple <- tm_shape(seine) + tm_lines(col = "black")
tmap_arrange(orig, simple, ncol = 2)
#View original data
orig <- tm_shape(seine) + tm_lines(col = "black") + tm_layout(title = "Original")
orig
#simplify the gometry
seine_simp = st_simplify(seine, dTolerance = 2000)  # 2000 m
#view new data next to original data
simplify <- tm_shape(seine) + tm_lines(col = "black") + tm_layout(title = "Simplified")
tmap_arrange(orig, simplify, ncol = 2)
#see next chunk for size comparison
#original disk size
orig.disk <- object.size(seine)
print("Original disk size = ", orig.disk)
print(orig.disk)
#original disk size
orig.disk <- object.size(seine)
print("Original disk size")
print(orig.disk)
#simplified disk size
simp.disk <- object.size(seine_simp)
print("Simplified disk size")
print(simp.disk)
knitr::opts_chunk$set(echo = TRUE)
#libraries
library(sf)
library(terra)
library(dplyr)
library(spData)
library(tmap)
#data
data(seine)
nz_sfc = st_geometry(nz)
#use nz_sfc with a vector to shift
nz_sfc = st_geometry(nz)
#uncomment code below and create shift
# nz_shift <-
plot(nz_shift)
#uncomment code below and create shift
nz_shift <-nz_sfc + c(300, -500)
plot(nz_shift)
plot(nz_sfc, add = TRUE)
?plot
plot(nz_shift)
plot(nz_sfc, add = TRUE)
#use nz_sfc with a vector to shift
nz_sfc = st_geometry(nz)
#uncomment code below and create shift
nz_shift <-nz_sfc + c(3000, -5000)
#uncomment code below to map shift
tm_shape(nz_sfc) + tm_polygons(col = "gray") +
tm_shape(nz_shift) + tm_polygons(col = "red")
tm_shape(nz_shift) + tm_polygons(col = "red")
#uncomment code below to map shift
tm_shape(nz_sfc) + tm_polygons(col = "gray") + tm_shape(nz_shift) + tm_polygons(col = "red")
+ tm_shape(nz_shift) + tm_borders(col = "red")
#uncomment code below to map shift
tm_shape(nz_sfc) + tm_polygons(col = "gray") +
tm_shape(nz_shift) + tm_borders(col = "red")
install.packages("swirl")
swirl()
library(swirl)
swirl()
